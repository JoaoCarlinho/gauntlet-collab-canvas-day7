# AI Canvas Job Processing Architecture

## Quick Answer to Your Questions

**Q: Where would job logs be visible?**
**A:** Railway logs - same place as all your Python Flask logs

**Q: Is the job running on the same server as the Python code?**
**A:** YES - it runs in the same Railway container as a background thread

**Q: Does a job runner need to be configured?**
**A:** NO - it auto-starts when Flask starts (already configured)

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAILWAY CONTAINER                            â”‚
â”‚  (Single Python process running Flask app)                     â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   MAIN FLASK THREAD                      â”‚  â”‚
â”‚  â”‚  - Handles HTTP requests                                â”‚  â”‚
â”‚  â”‚  - API endpoints (/api/canvas, /api/ai-agent/*, etc)   â”‚  â”‚
â”‚  â”‚  - Socket.IO WebSocket connections                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â”‚ Spawns on startup                  â”‚
â”‚                           â†“                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              JOB PROCESSOR THREAD                        â”‚  â”‚
â”‚  â”‚  (background daemon thread)                              â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  Every 5 seconds:                                        â”‚  â”‚
â”‚  â”‚    1. Query database for 'queued' jobs                  â”‚  â”‚
â”‚  â”‚    2. If found, spawn worker thread                     â”‚  â”‚
â”‚  â”‚    3. Repeat                                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â”‚ Spawns worker threads              â”‚
â”‚                           â†“                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              JOB WORKER THREADS                          â”‚  â”‚
â”‚  â”‚  (up to 3 concurrent jobs)                               â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  For each job:                                           â”‚  â”‚
â”‚  â”‚    1. Initialize AIAgentService                          â”‚  â”‚
â”‚  â”‚    2. Call OpenAI API                                    â”‚  â”‚
â”‚  â”‚    3. Parse response                                     â”‚  â”‚
â”‚  â”‚    4. Save objects to PostgreSQL                         â”‚  â”‚
â”‚  â”‚    5. Emit WebSocket events                              â”‚  â”‚
â”‚  â”‚    6. Mark job as 'completed'                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  ALL LOGS GO TO STDOUT â†’ Railway Logs Dashboard               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Detailed Flow: From Request to Completion

### 1. **Job Creation** (API Request)
```
POST /api/ai-agent/create-canvas
â†“
ai_agent.py:create_canvas_with_ai()
â†“
AIJobService.create_canvas_job()
â†“
INSERT INTO ai_jobs (status='queued')
â†“
Return 202 Accepted with job_id
```

**Logs you'll see:**
```
[ai_job_service] Created AI job b1e5430d-494d-467f-91e1-702190132d88 for user WOUl6X...
```

### 2. **Job Discovery** (Background Thread)
```
job_processor._process_loop() [runs every 5 seconds]
â†“
SELECT * FROM ai_jobs WHERE status='queued' ORDER BY priority DESC, created_at ASC
â†“
If job found â†’ Spawn worker thread
```

**Logs you'll see:**
```
[job_processor] Processing job b1e5430d-494d-467f-91e1-702190132d88
```

### 3. **Job Processing** (Worker Thread)
```
ai_job_service.process_job()
â†“
UPDATE ai_jobs SET status='processing', started_at=NOW()
â†“
Try to initialize AIAgentService
â†“
OpenAIClientFactory.create_client()
â†“
ai_service.create_canvas_from_query()
â†“
OpenAI API call (chat.completions.create)
â†“
Parse response â†’ Create objects â†’ Save to DB
â†“
UPDATE ai_jobs SET status='completed', result_data={...}
```

**Logs you'll see:**
```
[ai_job_service] AI service initialized for job b1e5430d-494d-467f-91e1-702190132d88
[openai_client_factory] Creating OpenAI client with api_key only (no validation)
[openai_client_factory] OpenAI client created successfully (will validate on first use)
[ai_agent_service] Starting AI canvas creation for user WOUl6X...
[ai_agent_service] Sanitizing user query...
[ai_agent_service] Emitted ai_generation_started for request: abc123...
[ai_agent_service] Using OpenAI model: gpt-4
[ai_agent_service] OpenAI API call successful
[ai_agent_service] Parsed 5 objects from AI response
[ai_agent_service] Saved 5 objects to canvas f2c40e86...
[ai_agent_service] Emitted ai_generation_completed for request: abc123...
[ai_job_service] AI job b1e5430d-494d-467f-91e1-702190132d88 completed successfully
```

### 4. **Error Handling** (If Something Fails)
```
Exception occurs during processing
â†“
ai_job_service.process_job() catches exception
â†“
job.schedule_retry() or job.mark_failed()
â†“
UPDATE ai_jobs SET status='failed', error_message='...', retry_count=1
â†“
Emit 'ai_job_error' WebSocket event
```

**Logs you'll see:**
```
[ai_job_service] Failed to initialize AI service: OpenAI API key is required but not configured
[ai_job_service] AI job b1e5430d-494d-467f-91e1-702190132d88 failed: OpenAI API key is required...
```

---

## Log Locations

### **ALL LOGS ARE IN RAILWAY**

There's **only one place** to look for logs:

1. **Railway Dashboard**
   - Go to: https://railway.app/
   - Select project: `gauntlet-collab-canvas-day7-production`
   - Click on backend service
   - Click "Deployments" tab
   - Click on latest deployment
   - View logs in real-time

2. **Log Types You'll See:**

   **Startup Logs:**
   ```
   Starting Container
   Database connected successfully
   Job processor started successfully
   ```

   **HTTP Request Logs:**
   ```
   POST /api/ai-agent/create-canvas â†’ 202
   GET /api/ai-agent/job/b1e5430d.../status â†’ 200
   ```

   **Job Processing Logs:**
   ```
   [job_processor] Processing job b1e5430d...
   [ai_job_service] AI service initialized for job b1e5430d...
   [ai_agent_service] Starting AI canvas creation...
   [ai_agent_service] OpenAI API call successful
   [ai_job_service] AI job b1e5430d... completed successfully
   ```

   **Error Logs:**
   ```
   [ai_job_service] Failed to initialize AI service: ...
   [ai_agent_service] AI canvas creation failed: ...
   ```

---

## Job Runner Configuration

### **Already Configured - Auto-Starts**

The job processor is automatically started when Flask initializes:

**File:** `backend/app/__init__.py:515-521`
```python
# Start job processor (only if not already running)
from app.services.job_processor import job_processor
if not job_processor.running:
    job_processor.start()
    print("Job processor started successfully")
else:
    print("Job processor already running")
```

### **Configuration Settings**

**File:** `backend/app/config_modules/job_config.py`

```python
MAX_CONCURRENT_JOBS = 3        # Max jobs running at same time
PROCESSING_INTERVAL = 5        # Check for new jobs every 5 seconds
MAX_RETRIES = 3               # Retry failed jobs up to 3 times
RETRY_BACKOFF_BASE = 2        # Exponential backoff (2^retry_count minutes)
```

**Environment Variables (Optional):**
- `MAX_CONCURRENT_JOBS` - Default: 3
- `JOB_PROCESSING_INTERVAL` - Default: 5 seconds
- `MAX_JOB_RETRIES` - Default: 3

### **No External Job Runner Needed**

Unlike some systems that use:
- âŒ Celery (requires Redis/RabbitMQ)
- âŒ Bull (requires Redis)
- âŒ AWS Lambda (separate infrastructure)
- âŒ Google Cloud Tasks (separate service)

This system uses:
- âœ… Python threading (built-in)
- âœ… PostgreSQL (already have it)
- âœ… Runs in same process (no extra config)

---

## Monitoring Job Status

### **1. Via Debug Endpoint**
```bash
curl https://gauntlet-collab-canvas-day7-production.up.railway.app/api/ai-agent/debug/environment
```

**Response:**
```json
{
  "job_processor": {
    "running": true,
    "active_jobs": 0,
    "max_concurrent_jobs": 3,
    "processing_interval": 5
  },
  "recent_jobs": [
    {
      "id": "b1e5430d-494d-467f-91e1-702190132d88",
      "status": "queued",
      "created_at": "2025-10-28T20:54:55.766730",
      "started_at": null,
      "completed_at": null,
      "error_message": null,
      "retry_count": 0
    }
  ]
}
```

### **2. Via Health Endpoint**
```bash
curl https://gauntlet-collab-canvas-day7-production.up.railway.app/api/ai-agent/health
```

**Response:**
```json
{
  "status": "healthy",
  "database": "connected",
  "job_processor": {
    "running": true,
    "active_jobs": 0,
    "max_concurrent_jobs": 3
  }
}
```

### **3. Via Railway Logs**

Search for:
- `"Processing job"` - Job picked up
- `"AI job .* completed successfully"` - Job finished
- `"AI job .* failed"` - Job failed
- `"Failed to initialize AI service"` - Can't start OpenAI client

---

## Why Jobs Weren't Processing

### **Before Fix (Current State)**

```
1. Job created â†’ status='queued' âœ…
2. Job processor finds job âœ…
3. Worker thread spawned âœ…
4. Try to initialize AIAgentService âŒ FAILS HERE
   - OpenAIClientFactory tries to create client
   - Calls client.models.list() to test connection
   - Test fails (network/rate limit/key issue)
   - Returns None
   - AIAgentService.__init__ raises RuntimeError
5. Job marked as failed âŒ
```

**Railway Logs Would Show:**
```
[ai_job_service] Failed to initialize AI service: Failed to initialize OpenAI client
```

**BUT:**
- Job stays in 'queued' status (not marked failed properly)
- No retry scheduled
- Job processor doesn't log the error
- Looks like nothing is happening

### **After Fix (What Will Happen)**

```
1. Job created â†’ status='queued' âœ…
2. Job processor finds job âœ…
3. Worker thread spawned âœ…
4. Initialize AIAgentService âœ… SUCCEEDS NOW
   - OpenAIClientFactory creates client WITHOUT testing
   - Returns client immediately
   - AIAgentService.__init__ succeeds
5. Call OpenAI API âœ…
   - Validates API key on first actual use
   - If key invalid, clear error message
6. Create objects, save to DB âœ…
7. Job marked as completed âœ…
```

**Railway Logs Will Show:**
```
[job_processor] Processing job b1e5430d-494d-467f-91e1-702190132d88
[ai_job_service] AI service initialized for job b1e5430d...
[openai_client_factory] Creating OpenAI client with api_key only (no validation)
[openai_client_factory] OpenAI client created successfully
[ai_agent_service] Starting AI canvas creation...
[ai_agent_service] OpenAI API call successful
[ai_job_service] AI job b1e5430d... completed successfully
```

---

## Troubleshooting

### **Issue: "Job processor started successfully" but no jobs processing**

**Check:**
1. Are jobs in 'queued' status?
   ```bash
   curl .../api/ai-agent/debug/environment
   ```

2. Look for initialization errors in Railway logs:
   ```
   Failed to initialize AI service
   ```

3. Check if AIAgentService can initialize:
   ```json
   "ai_service": {"status": "FAILED"}  // â† Bad
   "ai_service": {"status": "INITIALIZED"}  // â† Good
   ```

### **Issue: Jobs processing but failing**

**Check Railway logs for:**
- OpenAI API errors (invalid key, rate limit, quota)
- Database errors (can't save objects)
- Parsing errors (can't parse OpenAI response)

### **Issue: No logs at all**

**Possible reasons:**
1. Railway deploying from wrong branch
2. Old code cached (force redeploy)
3. Container crashed (check deployment status)

---

## Summary

âœ… **Job runner IS configured** - auto-starts with Flask
âœ… **Logs ARE visible** - Railway logs dashboard
âœ… **Jobs RUN in same container** - Python threading
âœ… **No extra setup needed** - fully integrated

After your fix deploys, you should see full job processing logs in Railway showing the entire flow from job pickup to OpenAI API call to object creation! ğŸš€
